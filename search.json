[{"title":"Hello World","url":"/2025/09/19/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\n一、Quick Start1、Create a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"智驾学习","url":"/2025/09/29/transformer/","content":"一、雷达1、启动雷达$ ros2 launch rslidar_sdk start.py\n2、将雷达格式转为velodyne格式$ ros2 launch rs_to_velodyne rs_to_velodyne.launch.xml\n订阅：&#x2F;points_raw发布：&#x2F;veloyne_points3、将三维点云转化为二维点云$ ros2 launch pointcloud_to_laserscan start_launch.py\n订阅：  &#x2F;velodyne_points (PointCloud2)发布：  &#x2F;scan (LaserScan)二、IMU1、惯性导航驱动$ ros2 launch imu_node imu_node.launch.py\n注：惯导驱动文件，发布imu消息等，如果gps可用，也会发布二、相机1、驱动$ ros2 run car_cmd_interface car_cmd_interface_node\n订阅：&emsp;&emsp;&#x2F;cmd_vel（geometry_msgs::msg::Twist，主要使用linear.x作为速度，单位m&#x2F;s）&emsp;&emsp;&#x2F;angle（std_msgs::msg::Float32，单位为角度）&emsp;&emsp;&#x2F;control_cmd（car_msg::msg::VehicleState）发布：&emsp;&emsp;&#x2F;vehicle_info（car_msg::msg::VehicleState）","categories":["智驾-感知"],"tags":["智驾"]},{"title":"智驾框架","url":"/2025/11/02/study/","content":"一、感知1.1、摄像头1.1.1、启动摄像头# 启动单个摄像头ros2 run camera_driver camera_pub_node# 启动4个摄像头ros2 run camera_driver_all camera_pub_node_all\n注：由于摄像头本身的分辨率是1920×1080的，所以如果改成1080×720的就会裁剪，导致图像不完整\n注：发布的话题 – &gt; &#x2F;image_raw（sensor_msgs::msg::Image）1.2、启动摄像头conda activate yolo_ros   //激活环境（安装了pytorch(cuda 12.1)版本，支持GPU加速）ros2 launch yolo_bringup yolo.launch.py \t//目标检测ros2 launch yolo_bringup yolo.launch.py model:=yolov8m-seg.pt\t\t//实例分割ros2 launch yolo_bringup yolo.launch.py model:=yolov8m-seg.pt\t\t//人类姿态识别\n订阅话题 -- &gt;  /image_raw发布话题 -- &gt;              /yolo/detections - YOLO检测结果（主要输出）               /yolo/dbg_image - 调试图像（带检测框的可视化图像）--rviz中设置这个话题来看      --  &gt;              /yolo/dgb_bb_markers - 边界框标记（RViz中显示边界框）              /yolo/dgb_kp_markers - 关键点标记（如果检测人体关键点）              /yolo/tracking - 包含：带ID的跟踪目标信息，如果需要进行目标跟踪，用于持续跟踪同一物体。\n注：如果运行报错指出缺少依赖，不是没有安装，是路径没有正确设置//设置环境变量export PYTHONPATH=/home/nvidia/anaconda3/envs/yolo_ros/lib/python3.10/site-packages:$PYTHONPATH\n1.3、启动雷达ros2 launch rslidar_sdk start.py\n注：发布话题 –&gt;  &#x2F;rslidar_points1.4、启动IMU（底盘供电）# 进入/auto_driving_new/autodrive/src/driver/imu/ros2-imu-dirve-mainsource install/setup.bashros2 launch imu_node imu_node.launch.py\n发布话题 ---- &gt;              /AG041_Pub              /AG051_Pub              /AG072_Pub              /Gnss_Pub              /Imu_Pub              /imu_msg\n1.4、雷达和相机同时启动注：如果同时启动其中一个传感器卡死，就是带宽的问题，需要降低相机的帧率同时启动效果如下：\n二、底盘2.1、进入工作空间cd ~/your_workspace  #替换为你的工作空间\n2.2、编译car_msg功能包colcon build --packages-select car_msg #因为控制和底盘都依赖car_msg\n2.3、编译底盘模块和其他依赖colcon build\n2.4、刷新环境变量source install/setup.bash #每次打开终端都需要执行\n2.5、启动底盘节点ros2 run car_cmd_interface car_cmd_interface_node\n注意：可能会出现can0的问题，可以执行以下命令sudo busybox devmem 0x0c303018 w 0xc458sudo busybox devmem 0x0c303010 w 0xc400sudo busybox devmem 0x0c303008 w 0xc458sudo busybox devmem 0x0c303000 w 0xc400sudo modprobe cansudo modprobe can_rawsudo modprobe mttcan# 关闭can0sudo ip link set down can0# 启动，bitrate 500000 表示将 can0 接口的比特率设置为 500 kbpssudo ip link set can0 type can bitrate 500000# 打开can0sudo ip link set up can0\n2.6、查看车辆的状态信息# 可以先查看一下topic话题ros2 topic list#  查看 /vehicle_info话题ros2 topic echo /vehicle_info\n注：在启动底盘节点后会从底盘通过can0读取车辆状态数据发布到这个话题，最后在终端输出车辆信息2.7、给一个简单的控制命令查看车的反应情况ros2 topic pub -r 10 /control_cmd car_msg/msg/VehicleState &quot;&#123;&#x27;velocity&#x27;: 0.0, &#x27;steering&#x27;: 3.0, &#x27;brake&#x27;: 0.0, &#x27;gears&#x27;: 0, &#x27;led&#x27;: &#x27;no&#x27;, &#x27;battary&#x27;: 90.0&#125;&quot;\n注意car_msg的参数配置（如下图）\n可以查看一下长时间一个转角，然后突然给一个别的转角，反应如何三、slam建图3.1、lidarslam_ros23.1.1、启动雷达# 进入driver文件夹source install/setup.bash# 启动雷达驱动ros2 launch rslidar_sdk start.py# 启动slam运行launch文件ros2 launch lidarslam lidarslam.launch.py\n注：注意查看雷达话题名字，在lidarslam的yaml配置文件进行订阅和正确的配置可以通过这个查看雷达是否被slam配置节点（scan_matcher)所订阅ros2 topic info /rslidar_points --verbose \nscan_matcher成功订阅刚开始rviz只有一个坐标轴（正常），接下来移动小车，改变雷达的位置和朝向，采集更多环境点云，会逐渐出现点云地图（PointCloud2 组件）监控 &#x2F;tf话题,若出现 frame_id: “map”, child_frame_id: “base_link” 的变换，说明 map 坐标系生成，RViz 中设置 Fixed Frame: map 即可显示地图。ros2 topic echo /tf | grep &quot;map&quot;\n检查节点日志#若有 Update map 或 Published transform from map to base_link 日志，说明地图构建正常。ros2 topic echo /rosout | grep &quot;scan_matcher&quot;\n\n四、定位（lidar_localization_ros2）4.1、lidar_localization_ros2介绍基于预先生成的地图进行实时位姿估计\n4.2、配置好雷达话题和launch配置文件4.3、启动执行文件ros2 launch rslidar_sdk start.py  # 启动雷达 话题名称为/rslidar_points，消息类型为sensor_msgs/msg/PointCloud2（激光雷达点云数据） ros2 launch lidar_localization_ros2 lidar_localization.launch.py  # 启动执行文件ros2 topic info /rslidar_points --verbose # 查看lidar_localization是否  订阅雷达话题\n4.4、验证过程ros2 topic list | grep -E &quot;odom|pose&quot;  # 筛选位姿相关话题  输出/odom 和 /pcl_poseros2 topic info /odom --verbose | grep &quot;Publisher&quot;  # 查看 /odom 话题的发布节点ros2 topic info /pcl_pose --verbose | grep &quot;Publisher&quot; # 查看 /pcl_pose (这个为定位模块的发布位姿话题)\n# 验证 /pcl_pose 位姿是否随运动动态更新ros2 topic echo /pcl_pose --noarr\n验证结果如下：\n注：成功标志：数值随雷达运动实时更新，无固定不变或异常跳变4.5、RViz 可视化最终验证4.5.1、查看定位模块的加载地图的cpp文件，确定地图发布的话题查看lidar_localization_component.hpp，我这里的initial_map_pub_发布的地图话题是/initial_map，而不是/map\n注：在rviz中设置中就要配置&#x2F;initial_map4.5.2、启动雷达ros2 launch rslidar_sdk start.py\n4.5.3、启动定位执行launch文件ros2 launch lidar_localization_ros2 lidar_localization.launch.py  # 启动执行文件\n4.5.4、发布初始位姿，触发定位匹配# 发布初始位姿到 /initialpose 话题（地图原点）# 发布后，cloudReceived 函数会开始处理雷达点云，/pcl_pose 位姿会随雷达移动更新ros2 topic pub /initialpose geometry_msgs/msg/PoseWithCovarianceStamped &quot;&#123;header: &#123;frame_id: &#x27;map&#x27;&#125;, pose: &#123;pose: &#123;position: &#123;x: 0.0, y: 0.0, z: 0.0&#125;, orientation: &#123;w: 1.0&#125;&#125;&#125;&#125;&quot;\n注：为什么需要发布初始位姿，手动发布初始位姿是为了解决 “定位模块与实际环境的初始对齐问题”，激光雷达定位（如 NDT、ICP）属于一个相对匹配算法，需要一个 初始的 “猜测位置”，才能开始计算。手动发布初始位姿，相当于给算法一个 “接近真实位置的初始猜测”，让它能快速找到正确的匹配关系。总而言之不要完全依赖算法自动初始化。（后续可以加载到配置文件）（可加可不加，加之后会出现与初始位姿的抖动）4.5.5、RViz配置Fixed Frame -------  mapPointClound2 （地图） -------- Topic : /initial_map  显示预加载地图PointCloud2（实时雷达） ------ Topic: /rslidar_points 显示实时点云PoseWithCovariance   -------   Topic: /pcl_pose  显示定位位姿\n4.5.6、成功标志红色实时雷达点云与 /initial_map 地图点云精准重合移动雷达时，/pcl_pose 箭头平滑跟随，position.x/y 数值同步变化\n4.5.7、结果展示(..&#x2F;..&#x2F;MP4&#x2F;视频.mp4)\n注：视频传不上去五、规划5.1、发布栅格地图5.1.1、进入nav2工作空间cd ~/ros2_map_server_wscolcon build --packages-select nav2_map_server nav2_common nav2_util nav2_msgs --cmake-args -DCMAKE_BUILD_TYPE=Release # 第一次编译source install/setup.bash\n注意只source一次，不要换环境，下下来直接打开新终端启动5.1.2、启动地图服务cd ~/auto_drvingros2 run nav2_map_server map_server --ros-args -p yaml_filename:=map.yaml  # 启动即可# 然后激活，无报错即可ros2 lifecycle set /map_server configureros2 lifecycle set /map_server activateros2 topic echo /map | grep -A 10 &quot;info:&quot;  # 可以查看地图加载情况 (用作验证调试)ros2 topic echo /map nav_msgs/msg/OccupancyGrid  # 查看地图加载情况和位置信息 (用作验证调试)\n5.1.3、RViz可视化ros2 run rviz2 rviz2# 配置如下Fixed Frame ----- mapMap -----   Topic：/map\n注：如果出不来栅格地图，可以执行以下步骤pkill -f nav2_map_serverros2 run nav2_map_server map_server --ros-args -p yaml_filename:=map.yaml\n显示结果如下：\n5.2、进行规划操作—— 尝试过程   ——5.2.1、启动规划配置文件ros2 run nav2_planner planner_server --ros-args --params-file ~/auto_driving/nav2_params.yaml\n现在状态：planner_server 和 global_costmap.global_costmap 节点已成功启动，但处于「等待激活」状态（未进入 active 生命周期），需要手动触发激活才能正常工作。\n下一步：激活节点生命周期1、激活全局成本地图（失败）\n# 新终端执行ros2 lifecycle set /global_costmap.global_costmap configureros2 lifecycle set /global_costmap.global_costmap activate\n成功后，成本地图终端会显示 Activating 并加载地图数据。2、激活规划器（成功）\n# 同一终端继续执行ros2 lifecycle set /planner_server configureros2 lifecycle set /planner_server activate\n规划器终端会显示 Activating 并初始化规划算法（如 NavfnPlanner）3、确认节点已进入 active 状态\nros2 lifecycle get /global_costmap.global_costmap  # 应返回 activeros2 lifecycle get /planner_server                # 应返回 active\n接着走————-\n5.2.2、发布起始位姿$ ros2 topic pub /initialpose geometry_msgs/msg/PoseWithCovarianceStamped &quot;header:  frame_id: &#x27;map&#x27;pose:  pose:    position: &#123;x: 0.0, y: 0.0, z: 0.0&#125;    orientation: &#123;x: 0.0, y: 0.0, z: 0.0, w: 1.0&#125;  covariance: [0.25,0,0,0,0,0, 0,0.25,0,0,0,0, 0,0,0,0,0,0, 0,0,0,0,0,0, 0,0,0,0,0,0, 0,0,0,0,0,0.0685]&quot; -1\n5.2.3、发布目标位姿$ ros2 topic pub /goal_pose geometry_msgs/msg/PoseStamped &quot;header:  frame_id: &#x27;map&#x27;pose:  position: &#123;x: 1.0, y: 1.0, z: 0.0&#125;  orientation: &#123;x: 0.0, y: 0.0, z: 0.0, w: 1.0&#125;&quot; -1\n————————————————————————————卡到这了\n5.2.4、查看规划结果$ ros2 topic echo /plan nav_msgs/msg/Path\n———尝试结束———–—————–静态规划———————静态规划1、启动地图服务ros2 run nav2_map_server map_server --ros-args -p yaml_filename:=map.yaml\n2、启动nav2的planner_server服务ros2 run nav2_planner planner_server --ros-args --params-file /home/nvidia/auto_driving/nav2_params.yaml\n3、启动nav2_costmap_2d服务ros2 run nav2_costmap_2d nav2_costmap_2d --ros-args -r __ns:=/global_costmap -r __node:=global_costmap --params-file /home/nvidia/auto_driving/nav2_params.yaml\n4、同时激活ros2 run nav2_lifecycle_manager lifecycle_manager --ros-args -p autostart:=true -p node_names:=&quot;[&#x27;planner_server&#x27;, &#x27;global_costmap/global_costmap&#x27;]&quot;\n5、查看是否激活成功 –返回active [3] 代表成功ros2 lifecycle get /global_costmap/global_costmapros2 lifecycle get /planner_server\n6、发布目标命令，并查看路径话题ros2 action list # 查看action列表ros2 interface show nav2_msg/action/ComputePathToPose # 查看Action接口，用于系统生成从当前位置到目标位置的路径\n注：我编写了一个启动文件send_goal.py直接执行即可7、在RViz中查看路径—path的话题为&#x2F;path结果如下：\n注：这对于全局规划路线是实现了，但是没有考虑车自身的大小和路径的可行性（雷达点云数据未处理）—————–动态规划———————1、nav2框架的介绍BT Navigator Server统筹全局 包含三部分          - Planner Server：全局规划，基于静态地图进行规划          - Controller Server：局部规划，会对新增的障碍物信息也进行避障，实现动态规划          - Recovery Server：恢复层\n两个代价地图    1、Global Costmap         - Static Map Layer：静态地图层（SLAM建立完成的静态地图）         - Obstacle Map Layer：障碍物地图层（动态的记录传感器感知到的障碍物的信息）         - Inflation Layer：膨胀层（在以上两层地图上进行膨胀，防止机器人外壳撞上障碍物）    2、Local Costmap         - Obstacle Map Layer         - Inflation Layer\nTF树必须得通！！！【重要】TF树 ==  map -&gt; odom -&gt; base_link -&gt; [sensorframes]\n2、实现步骤2.1 启动雷达2.2 启动地图服务并激活2.3 构建TF树的结构：map -&gt; base_link -&gt; rslidarros2 launch static_tf.launch.py\n注：这里没有map转odom的原因是我没有用nav2的定位模块，用的是我的定位模块 , 只不过把我定位的输出位姿pcl_pose -&gt; &#x2F;amcl_pose2.4 启动nav2的导航框架ros2 launch nav2_bringup navigation_launch.py use_sim_time:=false map:=map.yaml\n注：确保 &#x2F;planner_server &#x2F;control_server  &#x2F;bt_navigator全部激活可以按照一下步骤操作：ros2 lifecyle get ___    得到active [3]代表激活成功ros2 lifecyle set ___ configureros2 lifecyle set ___ activate\n2.5 启动定位模块并完成pcl转nav2需要的amclros2 launch lidar_localization_ros2 lidar_localization.launch.pypython3 pcl_to_amcl.py \n2.6 启动nav2样式的rviz2rviz2 -d /opt/ros/humble/share/nav2_bringup/rviz/nav2_default_view.rviz\n注：nav2的rviz中配置的是laserscan二维点云，所以这里需要转一下ros2 run pointcloud_to_laserscan pointcloud_to_laserscan_node --ros-args -r cloud_in:=/rslidar_points -p target_frame:=base_link\n注：但是Nav2并非必须使用 LaserScan 格式，它同时原生支持sensor_msgs&#x2F;PointCloud2点云格式，二者均能为其代价地图提供障碍物感知数据2.7 实现效果如下视频上传不了，放到博客了，可以到github找\n六、雷达避障实现6.1、整体介绍1、执行的功能包是 laser_avoid，因为避障涉及控制和底盘信息，而控制和底盘信息依赖car_msg，所以需要colcon一下。2、订阅的是/control_cmd节点，注意在文件书写正确3、在文件中我写了好多调试打印，可以查看细节4、执行的节点是laser_obstacle_detector_2 ， 执行的是laser_avoid_2.cpp，所以注意配置文件的启动节点名称5、注意这个订阅的/scan，所以在launch中添加了rslidar_points → /scan模块，注意重映射6、手动发布控制命令会和雷达避障模块发布停止频率冲突\n6.2、操作过程colcon build --packages-select car_msgcolcon build --packages-select laser_avoidsource install/setup.bashros2 launch laser_avoid laser_avoid.launch.py   #注意调试打印信息ros2 run car_cmd_interface car_cmd_interface_node # 启动底盘\n6.2、实现效果站在车的设定1米安全范围内，车不会动，然后离开（障碍物小时）会恢复，然后突然到车跟前，他会立刻急停，反应速度很快七、跟踪算法7.1、启动了一下launch文件ros2 launch car_simple_follow start_all.launch.xml\n注：目前启动后光轮子转一下，没有任何别的反应，后续可以结合雷达急停模块实现一个闭环","categories":["智驾-框架"],"tags":["智驾"]},{"title":"nav2动态规划","url":"/2025/11/15/nav2/","content":"nav2的框架可以看智驾框架那篇博客\ntf树的结构如果是map-&gt;base_link-&gt;rslidar/imu，这个结构是可以实现动态规划路径的。但是后续底盘接收到新路径做出对应动作依赖这个结构就不可行了，因为车需要不断行走，不断规划，如果base_link挂在map下的话就无法感知车的真实位置，也无法做出动作，因为地图是静态的，所以需要更改可以用在小车身上的tf树结构，如下图所示\n注：不能只发送静态的map-&gt;odom，因为在定位的时候tf发出的事map-&gt;base_link，所以这里需要更改定位模块\n这样就可以实现动态规划了\n动态规划流程1、启动雷达ros2 launch rslidar_sdk start.py\n2、slam建图# 生成pcd地图（让车动起来建图）ros2 launch lidarslam lidarslam.launch.py# 保存pcd地图ros2 service call /map_save std_srvs/Empty# pcd转pgm栅格数据ros2 launch pcd2pgm pcd2pgm.launch.py# 保存pgn地图ros2 run nav2_map_server map_saver_cli -f map\n3、启动地图服务# 启动地图服务ros2 run nav2_map_server map_server --ros-args -p yaml_filename:=map.yaml# 配置并激活地图服务ros2 lifecycle set /map_server configureros2 lifecycle set /map_server activate\n4、发布静态转换ros2 launch static_tf.launch.py\n注：定位实现了odon-&gt;base_link，这个文件实现map-&gt;odom和base_link-&gt;rslidar，这样tf结构完整\n5、启动定位ros2 launch lidar_localization_ros2 lidar_localization.launch.py \n6、启动nav2的导航ros2 launch nav2_bringup navigation_launch.py use_sim_time:=false map:=map.yaml\n6、启动底盘source install/setup.bashsudo busybox devmem 0x0c303018 w 0xc458sudo busybox devmem 0x0c303010 w 0xc400sudo busybox devmem 0x0c303008 w 0xc458sudo busybox devmem 0x0c303000 w 0xc400sudo modprobe cansudo modprobe can_rawsudo modprobe mttcan# 关闭can0sudo ip link set down can0# 启动，bitrate 500000 表示将 can0 接口的比特率设置为 500 kbpssudo ip link set can0 type can bitrate 500000# 打开can0sudo ip link set up can0ros2 run car_cmd_interface car_cmd_interface_node\n7、启动rvizrviz2 -d /opt/ros/humble/share/nav2_bringup/rviz/nav2_default_view.rviz\n8、实现效果及问题- 给一个目标点，小车会规划路线并顺利绕障到达终点- 对于倒车的反应较慢- 对于行驶过程中的突然出现的障碍物避障不好- 定位在室内很好，但是在室外定位有一点偏差- 转角有一点点小\n9、问题及解决1、拐弯问题    -  底盘模块启动的节点是/vehicle_interface_node         -- /angle              → std_msgs/msg/Float32         -- /cmd_vel            → geometry_msgs/msg/Twist         -- /control_cmd        → car_msg/msg/VehicleState- Nav2 控制的确实是 /cmd_vel，底盘节点也在订阅 /cmd_vel- 刚开始不拐弯是因为底盘模块没有设置拐角，增加msg-&gt;angular.z即可- 转角太小直接修改msg-&gt;angular.z即可，但是也要避免转角太大（已设置）2、定位问题  - 问题：在室内定位没问题，但是在室外fitness &gt; 阈值、不收敛、跳变，NDT 丢定位了  - 原因：室外环境较广，16线雷达点云密度较稀疏，缺少先验初始位置导致定位不准确  - 解决办法：在室外启动odom + imu，因为odom + imu 会持续给先验，在每次启动定位后，用 2D Pose Estimate 给“当前实际位置”即可，初始位姿差不多就可以，让fitness不大于阈值阈值就可以，odom会自动进行位姿先验确定准确位姿3、急停问题  - 问题：在行驶过程中对突然出现的障碍物无法进行及时规划绕障  - 原因：nav2推理较慢（可能）  - 解决方法：结合雷达急停模块，当遇到突然出现的障碍物时雷达急停模块接管，给nav2留下规划和感知的时间，等障碍物离开后，沿着规划好的路线继续前进  - 思考：这样就需要雷达安全区比nav2的安全区大一些，以避免每次遇到障碍物就急停再规划4、倒车延迟问题  - 倒车延迟太大  问题1：直接给个车后方的目标点，距离太大的话直接反应不可达  问题2：在室内小区域内遇到前方拐角太小需要后退时延迟太大  原因：未知  解决方法：暂无5、slam建图问题  - 问题1：slam建完的pcd地图，在定位模块使用的时候点云密度过于稀疏，也就是过滤的太多或者建图就不好  - 问题2：slam建完的pcd图转pgm栅格地图过滤的不行  - 原因：对室外的稀疏点云过度过滤，并且缺少对地面点云的处理  - 解决方法：调整点云过滤参数，增加地面过滤算法\n10、话题配置- Global Options的Fixed Frame    ----       map- TF如图- LaserScan  ------      /scan- Bumper Hit  -------    /mobile_base/sensors/bumper_pointcloud- Map --------   /map- Amcl Particle Swarm -------  /particle_cloud- Global Planner     - Global Costmap  -----  /global_costmap/costmap    - Path ----- /plan    - VoxelGril  ---- /global_costmap/voxel_marked_cloud    - Polygon  ---- /global_costmap/published_footprint- Controller    - Local Costmap   ---- /local_costmap/costmap    - Local Plan    ----   /local_plan    - VoxelGril   --- /local_costmap/voxel_marked_cloud    - Polygon  ---- /local_costmap/published_footprint    \n\n11、下一步计划1、解决未解决的问题2、优化已实现的不足3、尝试使用仿真的方法学习全覆盖动态规划思想\n","categories":["智驾-nav2动态规划"],"tags":["nav2"]},{"title":"智驾学习","url":"/2025/12/19/ORB_SLAM3/","content":"ORB_SLAM3算法这个算法就是在处理帧率和像素有点问题，整体难度不大，难点就是单目相机和数据的录制问题录制数据必须形成回环，得有关键点，不能移动太快问题：只能形成关键帧，至于后期要生导航规划所需的点云地图或者2d地图需要自己写算法进行处理，至于能不能用不确定\n1、启动单个摄像头ros2 run camera_driver camera_pub_node\n注：self.cap &#x3D; cv2.VideoCapture(?)  0是右，1是前，2是后，3是左（相机驱动文件）\n3、录制bag数据包ros2 bag record /image_raw\n\n4、播放bag包ros2 bag play .db3 --clock\n\n5、创建离线启动文件cd ORB_SLAM3chmod +x build.sh./build.sh\n注：执行 .&#x2F;Examples&#x2F;Monocular&#x2F;mono_tum 后出现 Usage: .&#x2F;mono_tum path_to_vocabulary path_to_settings path_to_sequence即可用\n6、导出所需要的图片和时间序列# 终端 1：播放 bagros2 bag play YOUR_BAG_NAME --clock# 终端 2：导出图片python3 dump_images.py\n注：这样导出的文件在 ~&#x2F;corridor中，此时txt时间序列不对，需要再根据相机帧率处理一下，读者可以自行优化更改处理代码\n# 按照帧率转时间序列python3 - &lt;&lt; &#x27;EOF&#x27;import osimage_dir = &#x27;rgb&#x27;fps = 20.0dt = 1.0 / fpsfiles = sorted(f for f in os.listdir(image_dir) if f.endswith(&#x27;.png&#x27;))with open(&#x27;rgb.txt&#x27;, &#x27;w&#x27;) as f:    for i, name in enumerate(files):        t = i * dt        f.write(f&quot;&#123;t:.9f&#125; &#123;image_dir&#125;/&#123;name&#125;\\n&quot;)        # 举例: 0.000000000 rgb/000000.png        #       0.050000000 rgb/000001.pngEOF\n7、离线跑ORB-SLAM3 单目建图./Examples/Monocular/mono_tum Vocabulary/ORBvoc.txt Examples/Monocular/cam_3.yaml ~/corridor\n注：生成关键帧序列 注：你会看到：   左边：图像+特征点   右边：3D 轨迹 + 稀疏点云\n8、补充：使用ros2跑export LD_LIBRARY_PATH=$HOME/ht/ORBSLAM3/ORB-SLAM3-STEREO-FIXED-master/lib:$LD_LIBRARY_PATHsource ~/ht/ORBSLAM3/ORB_SLAM3_ROS2-main/install/local_setup.bashros2 run orbslam3 mono ~/ht/ORBSLAM3/ORB_SLAM3_ROS2-main/src/vocabulary/ORBvoc.txt ~/ht/ORBSLAM3/ORB_SLAM3_ROS2-main/src/config/monocular/cam_3.yaml --ros-args -r /camera/image_raw:=/image_raw -r /camera/camera_info:=/camera_info\n注：也要关闭viewer，否则也会在建图的过程中直接段错误，程序终端结束进程\n","categories":["智驾-视觉slam"],"tags":["视觉slam"]},{"title":"智驾学习","url":"/2025/12/19/sys_time/","content":"雷达和相机时间软同步主要思想\n由于原始的雷达点云数据有自己的时间帧，而相机在启动时就打上系统时间帧了，并且原始雷达点云数据和相机原始数据时间差本身就大，在就需要也给雷达打上系统时间帧，然后再根据雷达和点云数据进行在一个阈值内融合并发布，超出阈值的就截下来。对于实验室Jetson小车来说，用原始相机数据（1920×1080）太大，所以在相机驱动中给他进行了格式转换和压缩，并且在融合时订阅的是原始相机数据\n注：后期可以尝试用imu进行时间同步\n1、启动雷达和相机source install/setup.bashros2 launch rslidar_sdk start.pysource install/setup.bashros2 run camera_driver camera_pub_node\n\n2、给雷达打系统时间帧source install/setup.bashros2 run sys_time stamp_relay_node\n\n3、对齐发布（0.2ms内）source install/setup.bashros2 run sys_time sync_node\n\n注：可以通过一下命令查看发布的帧以及丢掉多少\nros2 topic echo /image_raw/compressed --field header.stampros2 topic echo /rslidar_points_stamp --field header.stamp\n\n4、录同步后的bag数据包ros2 bag record /sync/lidar /sync/img/compressed /camera_info\n","categories":["智驾-时间同步"],"tags":["时间软同步"]},{"title":"智驾学习","url":"/2025/12/19/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%95%B4%E4%BD%93%E5%A4%96%E5%8F%82tf%E6%A0%91/","content":"imu_link + camera_link + rslidar + base_link首先要搞明白base_link是个什么东西，以及怎么想base_link只是一个坐标系，地图定位的坐标原点base_link在odom中最初可以理解为和odom重合的坐标原点在外参标定定义的时候，以这个点（这个点在地上）为基础进行 “造车”\n\n1、相机内参标定（ROS2单目相机标定）教程地址：https://blog.csdn.net/qq_27865227/article/details/123198498\ncd ~/hcj/calibration/image_pipelineros2 run camera_calibration cameracalibrator --size 7x9 --square 0.20 image:=/image_raw camera:=/my_camera\n注：这个方法是基于棋盘格的标定方法\n2、base_link  -&gt; rslidar0 0 1.0 0 0 0\n\n3、雷达和imu   rslidar  -&gt;  imu_link0.36 -0.07 -0.55 179.762270 0.070193 -4.322902\n\n4、雷达到相机# rslidar  -&gt;  camera_front&quot;results&quot;: &#123;    &quot;T_lidar_camera&quot;: [      0.16550511772856422,      -0.0003163653217201284,      -0.041388052276160554,      0.5042146903695429,      -0.4975212735222683,      0.5002103555111131,      0.49802583130573863    ]# rslidar  -&gt;  camera_right&quot;results&quot;: &#123;    &quot;T_lidar_camera&quot;: [      0.0031314587226820016,      -0.23814783903240186,      -0.049170490956282044,      0.011944211869822285,      0.7193899174882676,      -0.6943875953975415,      -0.012702353209248417    ]# rslidar  -&gt;  camera_rear&quot;results&quot;: &#123;    &quot;T_lidar_camera&quot;: [      -0.17550511772856422,      -0.0003163653217201284,      -0.041388052276160554,      0.49969541,      0.51744975,      -0.48255025,      0.49969541    ]# rslidar  -&gt;  camera_left&quot;results&quot;: &#123;    &quot;T_lidar_camera&quot;: [      0.0031314587226820016,      0.23814783903240186,      -0.049170490956282044,      0.69465837,      0.0,      0.0,      0.71933980    ]\n5、启动TF树结构ros2 launch orin_launch static_sensors_tf.launch.py\n注：启动轮式里程计就可以看到完整的TF结\n6、查看tf树# 查看tf树ros2 run tf2_tools view_frames# 或者rqt实时查看tf树结构ros2 run rqt_tf_tree rqt_tf_tree# 查看tf树中某两个传感器的相对位置ros2 run tf2_ros tf2_echo camera_right camera_rear\n最终结果如下图：注：这样任何一个传感器之间和base_link之间的位置都知道了\n","categories":["智驾-内外参标定"],"tags":["TF树"]},{"title":"智驾学习","url":"/2025/12/19/%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A/","content":"雷达相机外参标定 - direct_visual_lidar_calibration1、录同步数据source install/setup.bashros2 run camera_driver camera_pub_nodesource install/setup.bashros2 launch rslidar_sdk start.pysource install/setup.bashros2 run sys_time sync_noderos2 bag record /sync/lidar /sync/img/compressed /camera_info\n注：录得场景尽可能特征点多，多录几个角度\n3、处理数据ros2 run direct_visual_lidar_calibration preprocess \\  /home/nvidia/auto_driving/bag0 \\  /home/nvidia/auto_driving/bag0_pre_v2 \\  -adv \\  --image_topic /sync/img/compressed \\  --points_topic /sync/lidar \\  --camera_info_topic /camera_info\n\n4、进行标定# 4.1 加载环境变量export PYTHONPATH=$PYTHONPATH:/home/nvidia/hcj/calibration/ros2_ws/src/SuperGluePretrainedNetwork# 4.2 用录的数据跑 SuperGlue 匹配并自动估计初始位姿ros2 run direct_visual_lidar_calibration find_matches_superglue.py \\  /home/nvidia/auto_driving/bag0_pre_v2ros2 run direct_visual_lidar_calibration initial_guess_auto \\  /home/nvidia/auto_driving/bag1_pre_v2# 4.3 优化标定ros2 run direct_visual_lidar_calibration calibrate \\  /home/nvidia/auto_driving/bag1_pre_v2# 注：因为我们的特征点以及传感器偏差，并且该算发出就是优化算法，所以要自己先给一个接近真值的数据，这样优化后的结果很不错# 4.4 查看标定结果（可选）ros2 run direct_visual_lidar_calibration viewer \\  /home/nvidia/auto_driving/bag1_pre_v\n\n注：尽量进行SuperGlue匹配，效果会更好，如果小车蓝屏，可以暂时关闭雷达等进程放松带宽\n","categories":["智驾-雷达相机外参标定"],"tags":["外餐标定"]},{"title":"智驾学习","url":"/2025/12/19/%E9%9B%B7%E8%BE%BE%E7%9B%B8%E6%9C%BA%E8%9E%8D%E5%90%88%E5%BB%BA%E5%9B%BE/","content":"雷达相机融合建图 - RTAB-Map1、轮式里程计每次启动底盘前都执行一下source install/setup.bashsudo busybox devmem 0x0c303018 w 0xc458sudo busybox devmem 0x0c303010 w 0xc400sudo busybox devmem 0x0c303008 w 0xc458sudo busybox devmem 0x0c303000 w 0xc400sudo modprobe cansudo modprobe can_rawsudo modprobe mttcan# 关闭can0sudo ip link set down can0# 启动，bitrate 500000 表示将 can0 接口的比特率设置为 500 kbpssudo ip link set can0 type can bitrate 500000# 打开can0sudo ip link set up can0\n\n启动底盘节点ros2 run car_cmd_interface car_cmd_interface_node\n\n启动轮式里程计python3 wheel_odometry_node.py\n\n测试距离，查看行走的真实距离是否和终端打印的是否一致ros2 interface show car_msg/msg/VehicleStateros2 topic echo /wheel_odom | grep -A 3 &quot;position&quot;\n\n轮式里程计和imu融合发布&#x2F;odomros2 launch orin_launch ekf_localization.launch.py\n\n2、启动rtabmap启动节点ros2 launch rtabmap_launch rtabmap.launch.py   stereo:=false localization:=false   icp_odometry:=false visual_odometry:=false   depth:=false   subscribe_rgb:=true   subscribe_rgbd:=false   rgb_topic:=/sync/img   camera_info_topic:=/camera_info   subscribe_scan:=false   subscribe_scan_cloud:=true   scan_cloud_topic:=/sync/lidar   frame_id:=base_link   odom_topic:=/odom   use_sim_time:=true   qos:=2 approx_sync:=true   rtabmap_viz:=true rviz:=true   rtabmap_args:=&quot;--Reg/Strategy 1 --Icp/VoxelSize 0.05&quot;\n\n3、查看生成的db文件rtabmap-databaseViewer ~/.ros/rtabmap.db\n注：直接可以导出所需的pcd文件和pgm栅格地图\n实验过程图如下\n\n\n\n","categories":["智驾-融合建图"],"tags":["融合建图（轮式里程计）"]}]